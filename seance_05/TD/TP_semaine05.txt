TAL²

Semaine 5

	    TP: Influence de la taille de la fenêtre sur les embeddings distributionnels

   L'objectif du TP est d'observer l'influence de la taille de la fenêtre utilisée lors de
   l'élaboration d'embeddings statiques par comptage de co-occurrences. L'hypothèse est que les mots
   qui partagent des contextes étroits (de taille 3 par exemple) sont plutôt des mots qui partagent
   des propriétés morpho-syntaxiques, alors que des mots qui partagent des contextes plus larges
   vont sans doute plutôt partager des propriétés sémantiques.

   Pour ce faire, on va passer par les étapes suivantes :

   - Choix d'un corpus, et d'une liste de 10 mots variés (le choix peut dépendre des corpus choisis)

   - Calcul d'une matrice terme-terme pour une taille de fenêtre donnée

   - Pour chacun des mots choisis, extraction des 10 mots les plus similaire (cosine_similarity)

   - Même opération avec une autre taille de fenêtre et comparaison des listes de mots.




Quelques détails: 



  1. A partir d'un corpus segmenté et tokenisé, faire en sorte de créer un dictionnaire dont les
     entrées sont les tokens et qui associe à chaque token la liste des tokens qui apparaissent dans
     un voisinage de 2t tokens autour de lui.
     
  2. En utilisant CountVectorizer (de scikit-learn), construire une matrice terme-terme à partir du dictionnaire.

  3. En utilisant la fonction cosine_similarity, calculer la matrice de similarité entière

  4. Rechercher chacun des mots choisis et trouver les 10 tokens les plus proches. 

 



